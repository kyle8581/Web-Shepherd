<!-- <p align="left">
  <img src="assets/shepherd_emoji.png" alt="WEB-SHEPHERD Logo" width="100" style="vertical-align: middle; display: inline-block; margin-right: 10px"/>
  <h1 style="font-weight: bold; margin: 0; display: inline-block; vertical-align: middle">Web-Shepherd: Advancing Process Reward Models for Web Agents</h1>
</p> -->
<table>
<tr>
<td><img src="assets/shepherd_emoji.png" alt="WEB-SHEPHERD Logo" width="150"/></td>
<td><h1 style="margin: 0;">Web-Shepherd: Advancing Process Reward Models for Web Agents</h1></td>
</tr>
</table>


<!-- [![Paper](https://img.shields.io/badge/Paper-Preprint-informational?logo=arxiv)](assets/WebShepherd.pdf) -->
<!-- [![arXiv](https://img.shields.io/badge/arXiv-Preprint-red?logo=arxiv)](assets/WebShepherd.pdf) -->
[![PDF](https://img.shields.io/badge/PDF-Preprint-red?logo=arxiv)](assets/WebShepherd.pdf)
[![Model](https://img.shields.io/badge/Model-HuggingFace-informational?logo=huggingface)](https://huggingface.co/WebShepherd/web-shepherd-base)
[![Hugging Face Demo](https://img.shields.io/badge/Demo-Huggingface-blue.svg?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEiIHdpZHRoPSI2MDAiIGhlaWdodD0iNjAwIj48cGF0aCBkPSJNMTI5IDExMWMtNTUgNC05MyA2Ni05MyA3OEwwIDM5OGMtMiA3MCAzNiA5MiA2OSA5MWgxYzc5IDAgODctNTcgMTMwLTEyOGgyMDFjNDMgNzEgNTAgMTI4IDEyOSAxMjhoMWMzMyAxIDcxLTIxIDY5LTkxbC0zNi0yMDljMC0xMi00MC03OC05OC03OGgtMTBjLTYzIDAtOTIgMzUtOTIgNDJIMjM2YzAtNy0yOS00Mi05Mi00MmgtMTV6IiBmaWxsPSIjZmZmIi8+PC9zdmc+)](https://huggingface.co/spaces/WebShepherd/Project-Web-Shepherd)

Web-Shepherd is the **first process reward model (PRM)** designed specifically for web agents. It evaluates trajectories at the step level to provide interpretable and cost-efficient feedback for both learning and inference-time decision making in web navigation tasks.

---

## ğŸš€ Overview

Recent multimodal language models (MLLMs) have made progress in web automation but struggle with long-horizon planning and cost efficiency. To tackle this, Web-Shepherd introduces:

- **WebPRM Collectionn**: A dataset with 40K+ step-level preference annotations and structured checklists.
- **WebRewardBench**: A benchmark to test PRM effectiveness across diverse web tasks.
- **Web-Shepherd**: A PRM trained to provide step-wise feedback and reward using structured subgoal checklists.

---

## ğŸ§  Key Features

- âœ… Step-level trajectory evaluation for web agents
- ğŸ§¾ Checklist-guided reward modeling for interpretability
- ğŸ’° 100Ã— cost reduction compared to prompting GPT-4o
- ğŸ“ˆ Outperforms GPT-4o-mini by **10.9 points** on WebArena-lite
- ğŸ”„ Supports both reward assignment and agent refinement

---

## ğŸ’ Assets

| Resource | Description | Size | Link |
|----------|-------------|------|------|
| WebPRM Collection | Step-level preference annotations with structured checklists | 40K+ annotations | [ğŸ¤— huggingface](https://huggingface.co/datasets/LangAGI-Lab/WebPRMCollection_preference_pair) |
| WebRewardBench | Comprehensive benchmark for evaluating PRM effectiveness | 1000+ test cases | [ğŸ¤— huggingface](https://huggingface.co/datasets/LangAGI-Lab/WebRewardBench) |
| Web-Shepherd (3B, text-only) | Trained process reward model for web navigation | 350M parameters | [ğŸ¤— huggingface](https://huggingface.co/WebShepherd/web-shepherd-base) |
| Web-Shepherd (3B, ğŸ–¼ï¸ multimodal) | Trained process reward model for web navigation | 350M parameters | [ğŸ¤— huggingface](https://huggingface.co/WebShepherd/web-shepherd-base) |
| Web-Shepherd (8B, text-only) | Enhanced version with improved performance | 1.3B parameters | [ğŸ¤— huggingface](https://huggingface.co/WebShepherd/web-shepherd-large) |


## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ webshepherd/                 # Source code for the model
â”‚   â”œâ”€â”€ models/                  # Model architecture & training
â”‚   â”œâ”€â”€ data/                    # Dataset loading and processing
â”‚   â””â”€â”€ inference/               # Inference utilities (e.g., Best-of-n, feedback)
â”œâ”€â”€ scripts/                     # Training & evaluation scripts
â”œâ”€â”€ configs/                     # Model configs and experiment settings
â”œâ”€â”€ data/                        # Downloaded or generated datasets
â”‚   â”œâ”€â”€ webprm_collection/       # Annotated instructions, checklists, and actions
â”‚   â””â”€â”€ webrewardbench/          # Meta-evaluation benchmark
â”œâ”€â”€ demo/                        # Hugging Face Space setup (optional)
â”œâ”€â”€ results/                     # Logs and evaluation outputs
â””â”€â”€ README.md
```
